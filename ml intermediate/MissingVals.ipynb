{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f77f1ce-3456-42db-af24-8a638936616d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4367834-194b-4fd8-a4bb-9da6fe65e5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('~/JProjects/kaggle/data/melb_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a77dda4-d852-4630-a5d0-5a1e9c022210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select target\n",
    "y = data.Price\n",
    "\n",
    "# To keep things simple, we'll use only numerical predictors\n",
    "melb_predictors = data.drop(['Price'], axis=1)\n",
    "X = melb_predictors.select_dtypes(exclude=['object'])\n",
    "\n",
    "# Divide data into training and validation subsets\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d070483d-8e89-43b4-a8de-0c8a09e45253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for comparing different approaches\n",
    "def score_dataset(X_train, X_valid, y_train, y_valid):\n",
    "    model = RandomForestRegressor(n_estimators=10, random_state=0)\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_valid)\n",
    "    return mean_absolute_error(y_valid, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95af723-f1e3-40e7-a944-faf86b600727",
   "metadata": {},
   "source": [
    "There are three approaches how to work with missing values in the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75c41ae-76fa-4cbf-bc65-82b4785a0f19",
   "metadata": {},
   "source": [
    "## Drop columns with missing values\n",
    "\n",
    "Unless most values in the dropped columns are missing, the model loses access to a lot of (potentially useful!) information with this approach. As an extreme example, consider a dataset with 10,000 rows, where one important column is missing a single entry. This approach would drop the column entirely!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a2f2693-1058-4262-8b86-02e72c9be608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 1 (Drop columns with missing values):\n",
      "183550.22137772635\n"
     ]
    }
   ],
   "source": [
    "# Get names of columns with missing values\n",
    "cols_with_missing = [col for col in X_train.columns\n",
    "                     if X_train[col].isnull().any()]\n",
    "\n",
    "# Drop columns in training and validation data\n",
    "reduced_X_train = X_train.drop(cols_with_missing, axis=1)\n",
    "reduced_X_valid = X_valid.drop(cols_with_missing, axis=1)\n",
    "\n",
    "print(\"MAE from Approach 1 (Drop columns with missing values):\")\n",
    "print(score_dataset(reduced_X_train, reduced_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ca86f5-1878-4538-ab4a-6c43fc5d0332",
   "metadata": {},
   "source": [
    "## Imputation\n",
    "\n",
    "Imputation fills in the missing values with some number. For instance, we can fill in the mean value along each column.\n",
    "It gives more accurate model than just dropping columns entirely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "40e64e1b-7df6-410f-bcfc-0231de73cd39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 2 (Imputation)\n",
      "178166.46269899711\n"
     ]
    }
   ],
   "source": [
    "# Imputation\n",
    "imputer = SimpleImputer()\n",
    "imputed_X_train = pd.DataFrame(imputer.fit_transform(X_train))\n",
    "imputed_X_valid = pd.DataFrame(imputer.transform(X_valid))\n",
    "\n",
    "# Imputer removed columns; put them back\n",
    "imputed_X_train.columns = X_train.columns\n",
    "imputed_X_valid.columns = X_valid.columns\n",
    "\n",
    "print(\"MAE from Approach 2 (Imputation)\")\n",
    "print(score_dataset(imputed_X_train, imputed_X_valid, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24347fcc-7f0e-4102-9104-8011819340d6",
   "metadata": {},
   "source": [
    "## An Extension to Imputation\n",
    "\n",
    "Imputation is the standard approach, and it usually works well. However, imputed values may be systematically above or below their actual values (which weren't collected in the dataset). Or rows with missing values may be unique in some other way. In that case, your model would make better predictions by considering which values were originally missing.\n",
    "\n",
    "In this approach, we impute the missing values, as before. And, additionally, for each column with missing entries in the original dataset, we add a new column that shows the location of the imputed entries.\r\n",
    "\r\n",
    "In some cases, this will meaningfully improve results. In other cases, it doesn't help at all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6e5fcb84-13c0-45ba-aeea-152b6545a23a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE from Approach 3 (An Extension to Imputation):\n",
      "178927.503183954\n"
     ]
    }
   ],
   "source": [
    "# We impute the missing values, while also keeping track of which values were imputed\n",
    "\n",
    "# Make copy to avoid changing original data (when imputing)\n",
    "X_train_plus = X_train.copy()\n",
    "X_valid_plus = X_valid.copy()\n",
    "\n",
    "# Make new columns indicating what will be imputed\n",
    "for col in col_w_missing:\n",
    "    X_train_plus[col + 'was_missing'] = X_train_plus[col].isnull()\n",
    "    X_valid_plus[col + 'was_missing'] = X_valid_plus[col].isnull()\n",
    "\n",
    "# Imputation\n",
    "imputer = SimpleImputer()\n",
    "imputed_X_train_plus = pd.DataFrame(imputer.fit_transform(X_train_plus))\n",
    "imputed_X_valid_plus = pd.DataFrame(imputer.transform(X_valid_plus))\n",
    "\n",
    "# Put columns back\n",
    "imputed_X_train_plus.columns = X_train_plus.columns\n",
    "imputed_X_valid_plus.columns = X_valid_plus.columns\n",
    "\n",
    "print('MAE from Approach 3 (An Extension to Imputation):')\n",
    "print(score_dataset(imputed_X_train_plus, imputed_X_valid_plus, y_train, y_valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771f6c0-2d4e-4dbc-beea-4a0cef6a3e1b",
   "metadata": {},
   "source": [
    "As we can see, Approach 3 performed slightly worse than Approach 2.\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bb3259b-3142-4f34-96c1-a30b6dcac17f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10864, 12)\n",
      "Car               49\n",
      "BuildingArea    5156\n",
      "YearBuilt       4307\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Shape of training data (num_rows, num_columns)\n",
    "print(X_train.shape)\n",
    "\n",
    "# Number of missing values in each column of training data\n",
    "missing_val_count_by_column = (X_train.isnull().sum())\n",
    "print(missing_val_count_by_column[missing_val_count_by_column > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8033de1a-2af0-4556-ab4b-8246704b35ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a8ad41aa-668b-425e-bfad-81be8c4e3e5e",
   "metadata": {},
   "source": [
    "In scikit-learn's SimpleImputer, the fit_transform and transform methods serve different purposes:\r\n",
    "\r\n",
    "1. fit_transform: This method is used for training the imputer based on the data (fitting) and transforming the data at the same time. In other words, it learns the imputation strategy from the training data and immediately applies it to fill missing values. It returns the transformed dataset.\r\n",
    "`imputed_X_train = my_imputer.fit_transform(X_train)`\r\n",
    "Here, fit_transform is used on the training data (X_train), and the imputer is fit to this data. The imputer then applies the learned strategy to fill missing values in X_train and returns the imputed dataset.\r\n",
    "\r\n",
    "2. transform: This method is used for applying a previously learned imputation strategy to new data. It assumes that the imputer has already been fitted to some training data, and it applies the same imputation strategy to the new data without relearning from the new data.\r\n",
    "`imputed_X_valid = my_imputer.transform(X_valid)`\r\n",
    "Here, transform is used on the validation data (X_valid). It applies the imputation strategy learned from the training data to fill missing values in X_valid without refitting the imputer.\r\n",
    "\r\n",
    "In summary:\r\n",
    "Use fit_transform on your training data to both fit the imputer and transform the data.\r\n",
    "Use transform on new or unseen data to apply the learned imputation strategy without refitting the imputer.\r\n",
    "By using fit_transform on the training data and transform on the validation (or test) data, you ensure consistency in the imputation strategy between your training and validation datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b109b31e-438e-48a3-9e2d-e11bff02b026",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
